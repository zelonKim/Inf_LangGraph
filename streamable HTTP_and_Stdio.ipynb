{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fa86bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e3352ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "\n",
    "github_pat = os.getenv(\"GITHUB_PAT\")\n",
    "\n",
    "\n",
    "# mcp_client = MultiServerMCPClient({\n",
    "#     \"github\": {\n",
    "#         \"type\": \"http\",\n",
    "#         \"url\": \"https://api.githubcopilot.com/mcp/\",\n",
    "#         \"headers\": {\n",
    "#             \"Authorization\": f\"Bearer {github_pat}\"\n",
    "#         },\n",
    "#         \"transport\": \"streamable_http\",\n",
    "#     },\n",
    "# })\n",
    "\n",
    "\n",
    "mcp_client = MultiServerMCPClient({\n",
    "    \"github\" : {\n",
    "        \"command\": \"docker\",\n",
    "        \"args\": [\n",
    "            \"run\",\n",
    "            \"-i\",\n",
    "            \"--rm\",\n",
    "            \"-e\",\n",
    "            \"GITHUB_TOOLSETS\",\n",
    "            \"-e\",\n",
    "            \"GITHUB_PERSONAL_ACCESS_TOKEN\",\n",
    "            \"ghcr.io/github/github-mcp-server\"\n",
    "        ],\n",
    "        \"env\": {\n",
    "            \"GITHUB_TOOLSETS\": \"context, pull_requests\",\n",
    "            \"GITHUB_PERSONAL_ACCESS_TOKEN\": github_pat\n",
    "        },\n",
    "        \"transport\": \"stdio\",\n",
    "    }\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bbb7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_list = await mcp_client.get_tools()\n",
    "\n",
    "tool_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc05ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c6f050",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model = llm,\n",
    "    tools = tool_list,\n",
    "    state_modifier = (\"Use the tools provided to you to answer the user`s questions.\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c10e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def process_stream(stream_generator):\n",
    "    results = []\n",
    "    try:\n",
    "        async for chunk in stream_generator:\n",
    "            key = list(chunk.keys())[0]\n",
    "            \n",
    "            if key == 'agent':\n",
    "                content = chunk['agent']['messages'][0].content if chunk['agent']['messages'][0].content != '' else chunk['agent']['messages'][0].additional_kwargs\n",
    "                print(f\"'agent': '{content}'\")\n",
    "                \n",
    "            elif key =='tools':\n",
    "                for tool_msg in chunk['tools']['messages']:\n",
    "                    print(f\"'tool': '{tool_msg.content}'\")\n",
    "                    \n",
    "            results.append(chunk)\n",
    "        return results\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing streaming: {e}\")\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c895c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "query = \"\"\" 깃헙의 Pull Request를 확인하고 코드 리뷰를 작성해주세요.\n",
    "\n",
    "    PULL REQUEST URL: https://github.com/jasonkang14/sat-reading-client/pull/4\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "stream_generator = agent.astream({'messages': [HumanMessage(content=query)]})\n",
    "\n",
    "\n",
    "all_chunks = await process_stream(stream_generator)\n",
    "\n",
    "\n",
    "if all_chunks: \n",
    "    final_result = all_chunks[-1]\n",
    "    print(final_result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inf-langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
