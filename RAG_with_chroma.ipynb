{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879ae359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.문서 내용을 읽어옴. / # 2. 문서를 쪼갬.\n",
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter( # 긴 텍스트를 LLM이 처리하기 좋게끔 조각으로 쪼개주는 함수\n",
    "    chunk_size=1500, # 한 조각의 최대 문자 수\n",
    "    chunk_overlap=200, # 이전 조각과 겹치는 문자 수 (문맥 손실 방지)\n",
    ")\n",
    "\n",
    "loader = Docx2txtLoader(\"./tax.docx\") # 해당 문서를 읽기 위한 로더 객체를 생성함.\n",
    "document_list = loader.load_and_split(text_splitter=text_splitter) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2383c047",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "embedding = OpenAIEmbeddings(model='text-embedding-3-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97a0a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.임베딩하여 데이터베이스에 저장함.\n",
    "\n",
    "from langchain_chroma import Chroma # 로컬 기반 데이터베이스\n",
    "\n",
    "# 데이터베이스를 처음 생성함.\n",
    "# database = Chroma.from_documents(documents=document_list, \n",
    "#                                 embedding=embedding, # 문서에 임베딩을 적용하여 벡터로 변환함.\n",
    "#                                 persist_directory=\"./chroma\", # 영구 저장을 위한 데이터베이스 폴더를 생성함.\n",
    "#                                 collection_name=\"chroma-tax\", # 컬렉션을 생성함.                        \n",
    "#                                 )\n",
    "\n",
    "# 기존에 생성한 데이터베이스를 불러옴.\n",
    "database = Chroma(persist_directory=\"./chroma\",\n",
    "                 collection_name=\"chroma-tax\",\n",
    "                 embedding_function=embedding) # 사용자의 질문(쿼리)에 임베딩을 적용하여 벡터로 변환함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4c807b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '연봉 5천만원인 직장인의 소득세는 얼마인가요?'\n",
    "\n",
    "# 4.질문에 대한 유사도를 검색함.\n",
    "retrieved_docs = database.similarity_search(query, k=3) # 질문(쿼리)을 임베딩한 후, 데이터베이스에 저장된 모든 문서 조각들과 유사도를 비교한 후, 유사도가 가장 높은 k개만 반환함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57c58695",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56329ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.유사도 검색 문서와 질문을 LLM에게 전달함.\n",
    "\n",
    "prompt = f\"\"\"[identity]\n",
    "    - 당신은 최고의 한국 소득세 전문가 입니다\n",
    "    - [Context]를 참고해서 사용자의 질문에 답변해주세요\n",
    "    \n",
    "    [Context]\n",
    "    {retrieved_docs}\n",
    "    \n",
    "    Question: {query}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "541f6501",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_message = llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "71b5f333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'한국의 소득세는 여러 요인들에 따라 결정되며, 가장 중요한 요인은 과세표준입니다. 연봉 5천만 원인 직장인의 경우, 기본적인 소득세 부담을 계산하기 위해서는 먼저 공제 항목들을 고려해야 합니다. \\n\\n대부분의 경우, 연금보험료, 건강보험료, 고용보험료, 그리고 근로소득공제 등을 차감한 후 과세표준이 결정됩니다. 하지만 기본적인 과세표준을 고려하지 않고 단순히 연봉만으로 소득세를 계산한다면, 여기서는 한국의 기본 소득세율을 기준으로 대략적인 추정만 가능합니다.\\n\\n2023년 기준으로, 한국의 소득세율은 과세표준에 따라 달라집니다. 5천만 원의 경우, 과세표준이 1,200만 원 초과 ~ 4,600만 원 이하 구간에 속하므로, 15%의 세율이 적용됩니다. 따라서, 기본공제 등을 고려하지 않았을 때, 단순히 5천만 원에 대해 15%를 적용하면 약 750만 원이 소득세가 될 수 있습니다. \\n\\n그러나 실제 소득세는 개인의 공제 항목과 세액 공제를 고려한 후 계산되므로, 정확한 금액을 알고 싶다면 국세청의 소득세 계산기를 사용하는 것이 좋습니다. 또한, 근로소득세 공제나 추가적인 공제 항목들이 많으므로, 실제 부과되는 세금은 이보다 낮아질 수 있습니다.'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7de95cf",
   "metadata": {},
   "source": [
    "### RetrievalQA 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ccc5ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic import hub\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\") # RAG용 표준 프롬프트를 LangChain Hub에서 가져옴. (\"작성자/프롬프트명\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bdcac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.chains import RetrievalQA \n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type( # 벡터 검색, 프롬프트, LLM을 하나로 묶은 RAG 체인을 생성함. \n",
    "    retriever = database.as_retriever(search_kwargs={\"k\": 3}), # 데이터베이스를 리트리버 인터페이스로 변환함. / # 4.질문에 대한 유사도를 검색함.\n",
    "    chain_type_kwargs = {\"prompt\": prompt}, # 사용자 지정 프롬프트로 교체함.\n",
    "    llm = llm # 5.유사도 검색 문서와 질문을 LLM에게 전달함.\n",
    ")\n",
    "\n",
    "\n",
    "ai_message = qa_chain({\"query\": query})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stage2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
